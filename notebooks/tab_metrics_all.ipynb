{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd2178e-1463-46d1-914e-86007da2b134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyprojroot import here\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, auc, roc_curve\n",
    "\n",
    "from nutils import bootstrap_auc\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62d23e-6e0c-4cd8-9d83-b4f91125aa2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for path in Path(here() / 'data/processed/matrices/point').glob('*.csv'):\n",
    "    result = {}\n",
    "\n",
    "    \n",
    "    target = path.stem.split('-')[0]\n",
    "    model = path.stem.split('-')[1]\n",
    "    origin = path.stem.split('-')[2]\n",
    "    fs = path.stem.split('-')[3]\n",
    "    hpo = path.stem.split('-')[4]\n",
    "    name = f'{target}-{model}-{origin}-{fs}-{hpo}'\n",
    "    result['name'] = name\n",
    "\n",
    "    if target=='cri' or model=='guess':\n",
    "        continue\n",
    "\n",
    "    pred_name = f'{target}-{model}-{origin}-{fs}-{hpo}'\n",
    "    true_name = f'{target}'\n",
    "\n",
    "    true_path = f'data/processed/true_matrices/{true_name}.csv'\n",
    "    y_true = pd.read_csv(here() / true_path, parse_dates=True, index_col='Datetime')\n",
    "    \n",
    "    y_pred = pd.read_csv(path, parse_dates=True, index_col='Datetime').iloc[:,0]\n",
    "    idx = y_pred.dropna().index.intersection(y_true.dropna().index)\n",
    "    \n",
    "    y_pred = y_pred.loc[idx]\n",
    "    y_true = y_true.loc[idx]\n",
    "\n",
    "        \n",
    "    # F1 \n",
    "    result['F1'] = f1_score(y_true, y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    TN = cm[0][0]\n",
    "    FN = cm[1][0]\n",
    "    TP = cm[1][1]\n",
    "    FP = cm[0][1]\n",
    "\n",
    "    # Sensitivity, hit rate, recall, or true positive rate\n",
    "    result['TPR'] = TP/(TP+FN)\n",
    "    \n",
    "    # Specificity or true negative rate\n",
    "    result['TNR'] = TN/(TN+FP) \n",
    "    \n",
    "    # Precision or positive predictive value\n",
    "    result['PPV'] = TP/(TP+FP)\n",
    "    \n",
    "    # Negative predictive value\n",
    "    result['NPV'] = TN/(TN+FN)\n",
    "    \n",
    "    # Fall out or false positive rate\n",
    "    result['FPR'] = FP/(FP+TN)\n",
    "    \n",
    "    # False negative rate\n",
    "    result['FNR'] = FN/(TP+FN)\n",
    "    \n",
    "    # False discovery rate\n",
    "    FDR = FP/(TP+FP)\n",
    "\n",
    "    # Overall accuracy\n",
    "    result['ACC'] = (TP+TN)/(TP+FP+FN+TN)\n",
    "\n",
    "    result['FrPos'] = (y_true.sum() / y_true.shape[0]).values[0]\n",
    "\n",
    "    # AUROC\n",
    "    y_true = pd.read_csv(here() / f'data/processed/true_matrices/{true_name}.csv', index_col='Datetime')\n",
    "    y_pred = pd.read_csv(here() / f'data/processed/matrices/prob/{pred_name}.csv', index_col='Datetime')\n",
    "\n",
    "    df = pd.concat([y_true, y_pred], axis=1).dropna()\n",
    "    y_true = df.iloc[:,0]\n",
    "    y_pred = df.iloc[:,1]\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    _auc = auc(fpr, tpr)\n",
    "\n",
    "    # CI\n",
    "    lb, ub = bootstrap_auc(y_true, y_pred)\n",
    "\n",
    "    result['AUROC'] = f'{_auc:.2f} ({lb:.2f}-{ub:.2f})'\n",
    "\n",
    "    # PRAUC\n",
    "    y_true = pd.read_csv(here() / f'data/processed/true_matrices/{true_name}.csv', index_col='Datetime')\n",
    "    y_pred = pd.read_csv(here() / f'data/processed/matrices/prob/{pred_name}.csv', index_col='Datetime')\n",
    "\n",
    "    df = pd.concat([y_true, y_pred], axis=1).dropna()\n",
    "    y_true = df.iloc[:,0]\n",
    "    y_pred = df.iloc[:,1]\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred, pos_label=1)\n",
    "    _auc = auc(recall, precision)\n",
    "\n",
    "    lb, ub = bootstrap_auc(y_true, y_pred)\n",
    "\n",
    "    result['PRAUC'] = f'{_auc:.2f} ({lb:.2f}-{ub:.2f})'\n",
    "\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5cf3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(results).round(2)\n",
    "table = table.sort_values(by='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb168d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "table[['Target', 'Model', 'Origin', 'fs', 'hpo']] = table.name.str.split('-', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ce6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = table[['Target', 'Model', 'Origin', 'F1', 'TPR', 'TNR', 'PPV', 'NPV', 'FPR', 'FNR', 'ACC', 'AUROC', 'PRAUC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7a136",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.Origin = table.Origin.astype(int)\n",
    "table = table.sort_values(by=['Target', 'Origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727fc2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.Target = table.Target.str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680ffec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.Target = table.Target.replace({'Bed':'Bedoccupying', 'Med':'Medical', 'Sur':'Surgical'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c24d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = table.to_latex(\n",
    "    buf=here() / 'output/tables/metrics_all.tex',\n",
    "    float_format='%.2f',\n",
    "    position='H',\n",
    "    index=False,\n",
    "    label='tab:metrics_all',\n",
    "    caption='''\n",
    "    Performance of XGBoost, CatBoost and LightGBM in relation to one another.\n",
    "    '''\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
